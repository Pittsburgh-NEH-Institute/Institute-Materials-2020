{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEH Institute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## planning week 2 [suggestion]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time/Day | Monday | Tuesday | Wednesday | Thursday | Friday |\n",
    "--- | --- | --- | --- | --- | --- | \n",
    "9:00 - 10:00 | Modelling (basic principles) | Modelling (transcriptions) | Modelling (collation) | Modelling (annotations) | Modelling (queries and visualization) \n",
    "10:30 - 11:00 | Modelling (XML) | transcriptions / markup 1 | transcr./markup 2 | transcr./markup 3 | markup/annotation\n",
    "11:30 - 12:30 | Modelling (XML/TAG) | markup/tokenization 1 | tokenization 2 | annotation 1 | queries 1\n",
    "12:30 - 2:00 | lunch | lunch | lunch | lunch | lunch\n",
    "2:00 - 3:30 | Modelling (TAG) | normalization | collation | annotation 2 | queries 2\n",
    "3:30 - 4:00 | tea | tea | tea | tea | tea\n",
    "4:00 - 5:30 | review | review | collation | review | visualization/review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: each day starts with a recap on modelling, focused on the topic of the day (respectively tokenization, collation, annotation, queries), and ends with time for review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## updated planning week 2\n",
    "\n",
    "Time/Day | Monday | Tuesday | Wednesday | Thursday | Friday |\n",
    "--- | --- | --- | --- | --- | --- | \n",
    "9:00 - 10:30 | Model, syntax, and markup semantics | Computational pipelines | Modelling (collation), Transcription, Markup 2 | Modelling (annotations), Transcription, Markup 3 | Modelling (queries and visualization), Markup, Annotation \n",
    "10:30 - 11:00 |  Coffee break | Coffee break | Coffee break | Coffee break | Coffee break \n",
    "11:00 - 12:30 | Transcription with markup: XML | Tokenization 1 | Tokenization 2 | Annotation 1 | Queries 1 \n",
    "12:30 - 14:00 | lunch | lunch | lunch | lunch | lunch \n",
    "14:00 - 15:30 | XML as a tree | Normalization | Collation 1 | Text Analytics  | Queries 2\n",
    "15:30 - 16:00 | tea | tea | tea | tea | tea\n",
    "16:00 - 17:30 | Transcription with markup (LMNL/Alexandria) | Review | Collation 2 | Review | Visualization/Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2, Day 2: Tuesday, July 18\n",
    "\n",
    "## Synopsis\n",
    "\n",
    "Week 2, Day 2 introduces the idea of processing pipelines. It focuses on modular approaches to and algorithmic aspects of textual criticism. Outcome goals:\n",
    "\n",
    "* A modular understanding of textual criticism\n",
    "* Modular approaches to designing and implementing an edition\n",
    "\n",
    "## 9:00–10:30: Computational pipelines and text models\n",
    "\n",
    "Introduction to the idea of computational pipelines. \n",
    "\n",
    "The Gothenburg model (GM) of textual variation can serve as an example of a computational pipeline for the analysis of  textual variation. Focus here is not on textual variation: tokenization and normalization are necessary steps for every form of text processing and analysis.\n",
    "\n",
    "Concepts:\n",
    "* Tokenization\n",
    "* Normalization  \n",
    "\n",
    "## 11:00–12:30: Tokenization 1\n",
    "\n",
    "Tokenizing using different text models: plain text, TEI/XML. \n",
    "\n",
    "\"Simple\" tokenization: plain text\n",
    "* Exercises\n",
    "* Materials from the Amsterdam workshop?\n",
    "\n",
    "\n",
    "## 2:00–3:30: Normalization \n",
    "\n",
    "Normalization strategies\n",
    "* part of speech tagging\n",
    "* upper case / lower case normalization\n",
    "* etc.\n",
    "Issues\n",
    "Materials(?)\n",
    "\n",
    "## 4:00-5:30: Review\n",
    "\n",
    "Review section. Focus on participant's questions.  \n",
    "\n",
    "Alternative (in case all is clear) is to focus on markup as an expression of a data model. Expand upon the tokenization different kinds of text with markup (TEI) or, more generally, processing text models.\n",
    "\n",
    "# Week 2, Day 3: Wednesday, July 19\n",
    "\n",
    "## 9:00–10:30: Modelling (collation)\n",
    "\n",
    "Modelling: collation, transcription, and markup. \n",
    "Concepts.\n",
    "\n",
    "## 11:00–12:30: Tokenization 2\n",
    "\n",
    "Advanced tokenization: \n",
    "XML markup; Unicode; SoundEx.\n",
    "\n",
    "\n",
    "## 2:00–3:30: Collation 1\n",
    "\n",
    "Collation.  \n",
    "* Gothenburg Model (GM)\n",
    "* Theory of automated collation and textual variation analysis\n",
    "* Collation goals\n",
    "* Exercises with automated collation software: CollateX and Stemmaweb?\n",
    "* near-matching?\n",
    "\n",
    "\n",
    "## 4:00-5:30: Collation 2\n",
    "\n",
    "Collation and TEI/XML markup.  \n",
    "* different approaches to markup collation:\n",
    "    * flattening text\n",
    "    * passing along markup\n",
    "    * JSON (Sydney workshop)\n",
    "\n",
    "\n",
    "# Week 2, Day 4: Thursday, July 20\n",
    "\n",
    "Modelling: Annotations, Transcription. The goal is to make participants aware of \"Research-driven annotation\", letting them ask questions: \n",
    "1) What are the inherent properties of the text \n",
    "2) What do I need for my research? \n",
    "Discribe the computational pipeline: research questions → data model (including query facilities) → markup/annotation.\n",
    "\n",
    "## 9:00–10:30\n",
    "\n",
    "* Definition of Text Annotation\n",
    "* Pipeline of making annotations to text\n",
    "* Different approaches to and forms of annotation (allude e.g. to Alexandria)\n",
    "    * TEI\n",
    "    * Text-to-image linking; IIIF\n",
    "    * etc.\n",
    "\n",
    "## 11:00–12:30\n",
    "\n",
    "... \n",
    "\n",
    "\n",
    "## 2:00–3:30: Text analytics 1\n",
    "\n",
    "MK: Bag of words, text processing, text as tables, query the tables\n",
    "\n",
    "## 4:00-5:30: Text analytics 2\n",
    "\n",
    "MK: Bag of words, text processing, text as tables, query the tables (continued)\n",
    "\n",
    "# Week 2, Day 5: Friday, July 21\n",
    "\n",
    "## 9:00–10:30\n",
    "\n",
    "## 11:00–12:30\n",
    "\n",
    "## 2:00–3:30: Text analytics 3\n",
    "\n",
    "MK: Unsupervised learning, cluster analysis, PCA, paleographic analysis\n",
    "\n",
    "## 4:00-5:30: Text analytics 4\n",
    "\n",
    "MK: Unsupervised learning, cluster analysis, PCA, paleographic analysis (continued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
